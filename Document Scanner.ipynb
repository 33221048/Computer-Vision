{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Scanner\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example, we would be making a document scanner application. This is one of those posts which are inspired by amazing computer vision blogs at <a href=\"http://www.pyimagesearch.com/\">pyimagesearch.com</a>. For detailed explanations and cool computer vision projects, this website is strongly recommended. While going through examples from Pyimageserach or even this website, make sure you understand and make good use of the example projects. Think about how can you modify them and put them into use to solve real world problems. \n",
    "\n",
    "Coming back to our example, you should know scanning a document can be basically broken down into three simple steps:\n",
    "1. Detect edges.\n",
    "2. Use the edges in the image to find the contour (outline) representing the piece of paper being scanned.\n",
    "3. Apply a perspective transform to obtain the top-down view of the document."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Given below is the code of the document scanner:\n",
    "We would be using two modules for this app\n",
    "1. imutils.py (a slightly modified version to suit our purpose)\n",
    "2. transform.py\n",
    "Store these scripts in a folder named modules in your project directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## _modules/imutils.py_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import the necessary packages\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def translate(image, x, y):\n",
    "    # Define the translation matrix and perform the translation\n",
    "    M = np.float32([[1, 0, x], [0, 1, y]])\n",
    "    shifted = cv2.warpAffine(image, M, (image.shape[1], image.shape[0]))\n",
    "\n",
    "    # Return the translated image\n",
    "    return shifted\n",
    "\n",
    "def rotate(image, angle, center = None, scale = 1.0):\n",
    "    # Grab the dimensions of the image\n",
    "    (h, w) = image.shape[:2]\n",
    "\n",
    "    # If the center is None, initialize it as the center of the image\n",
    "    if center is None:\n",
    "        center = (w / 2, h / 2)\n",
    "\n",
    "    # Perform the rotation\n",
    "    M = cv2.getRotationMatrix2D(center, angle, scale)\n",
    "    rotated = cv2.warpAffine(image, M, (w, h))\n",
    "\n",
    "    # Return the rotated image\n",
    "    return rotated\n",
    "\n",
    "def resize(image, width = None, height = None, inter = cv2.INTER_AREA):\n",
    "    # initialize the dimensions of the image to be resized and grab the image size\n",
    "    dim = None\n",
    "    (h, w) = image.shape[:2]\n",
    "\n",
    "    # if both the width and height are None, then return the original image\n",
    "    if width is None and height is None:\n",
    "        return image\n",
    "\n",
    "    # check to see if the width is None\n",
    "    if width is None:\n",
    "        # calculate the ratio of the height and construct the dimensions\n",
    "        r = height / float(h)\n",
    "        dim = (int(w * r), height)\n",
    "\n",
    "    # otherwise, the height is None\n",
    "    else:\n",
    "        # calculate the ratio of the width and construct the dimensions\n",
    "        r = width / float(w)\n",
    "        dim = (width, int(h * r))\n",
    "\n",
    "    # resize the image\n",
    "    resized = cv2.resize(image, dim, interpolation = inter)\n",
    "\n",
    "    # return the resized image\n",
    "    return resized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## _modules/transform.py_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import numpy as np\n",
    "import cv2\n",
    "\n",
    "def order_points(pts):\n",
    "    # initialzie a list of coordinates that will be ordered such that the first entry in the list is the top-left,\n",
    "    # the second entry is the top-right, the third is the bottom-right, and the fourth is the bottom-left\n",
    "    rect = np.zeros((4, 2), dtype = \"float32\")\n",
    "\n",
    "    # the top-left point will have the smallest sum, whereas the bottom-right point will have the largest sum\n",
    "    s = pts.sum(axis = 1)\n",
    "    rect[0] = pts[np.argmin(s)]\n",
    "    rect[2] = pts[np.argmax(s)]\n",
    "\n",
    "    # now, compute the difference between the points, \n",
    "    # the top-right point will have the smallest difference, whereas the bottom-left will have the largest difference\n",
    "    diff = np.diff(pts, axis = 1)\n",
    "    rect[1] = pts[np.argmin(diff)]\n",
    "    rect[3] = pts[np.argmax(diff)]\n",
    "\n",
    "    # return the ordered coordinates\n",
    "    return rect\n",
    "\n",
    "def four_point_transform(image, pts):\n",
    "    # obtain a consistent order of the points and unpack them individually\n",
    "    rect = order_points(pts)\n",
    "    (tl, tr, br, bl) = rect\n",
    "\n",
    "    # compute the width of the new image, which will be the maximum distance between bottom-right and bottom-left\n",
    "    # x-coordiates or the top-right and top-left x-coordinates\n",
    "    widthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
    "    widthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
    "    maxWidth = max(int(widthA), int(widthB))\n",
    "\n",
    "    # compute the height of the new image, which will be the maximum distance between the top-right and bottom-right\n",
    "    # y-coordinates or the top-left and bottom-left y-coordinates\n",
    "    heightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
    "    heightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
    "    maxHeight = max(int(heightA), int(heightB))\n",
    "\n",
    "    # now that we have the dimensions of the new image, construct the set of destination points to obtain a \"birds eye view\",\n",
    "    # (i.e. top-down view) of the image, again specifying points in the top-left, top-right, bottom-right, and bottom-left order\n",
    "    dst = np.array([\n",
    "        [0, 0],\n",
    "        [maxWidth - 1, 0],\n",
    "        [maxWidth - 1, maxHeight - 1],\n",
    "        [0, maxHeight - 1]], dtype = \"float32\")\n",
    "\n",
    "    # compute the perspective transform matrix and then apply it\n",
    "    M = cv2.getPerspectiveTransform(rect, dst)\n",
    "    warped = cv2.warpPerspective(image, M, (maxWidth, maxHeight))\n",
    "\n",
    "    # return the warped image\n",
    "    return warped"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "And then finally our main script which imports these above two scripts as modules.\n",
    "## _scan.py_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "from modules.transform import four_point_transform\n",
    "from modules import imutils\n",
    "from skimage.filter import threshold_adaptive\n",
    "import numpy as np\n",
    "import argparse\n",
    "import cv2\n",
    "\n",
    "# load the image and compute the ratio of the old height\n",
    "# to the new height, clone it, and resize it\n",
    "image = cv2.imread(\"images/doc.jpg\")\n",
    "ratio = image.shape[0] / 500.0\n",
    "orig = image.copy()\n",
    "image = imutils.resize(image, height = 500)\n",
    "\n",
    "# convert the image to grayscale, blur it, and find edges\n",
    "# in the image\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "gray = cv2.GaussianBlur(gray, (5, 5), 0)\n",
    "edged = cv2.Canny(gray, 75, 200)\n",
    "\n",
    "# show the original image and the edge detected image\n",
    "print(\"STEP 1: Edge Detection\")\n",
    "cv2.imshow(\"Image\", image)\n",
    "cv2.imshow(\"Edged\", edged)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# find the contours in the edged image, keeping only the\n",
    "# largest ones, and initialize the screen contour\n",
    "(_,cnts, _) = cv2.findContours(edged.copy(), cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = sorted(cnts, key = cv2.contourArea, reverse = True)[:5]\n",
    "\n",
    "# loop over the contours\n",
    "for c in cnts:\n",
    "    # approximate the contour\n",
    "    peri = cv2.arcLength(c, True)\n",
    "    approx = cv2.approxPolyDP(c, 0.02 * peri, True)\n",
    "\n",
    "    # if our approximated contour has four points, then we\n",
    "    # can assume that we have found our screen\n",
    "    if len(approx) == 4:\n",
    "        screenCnt = approx\n",
    "        break\n",
    "\n",
    "# show the contour (outline) of the piece of paper\n",
    "print(\"STEP 2: Find contours of paper\")\n",
    "cv2.drawContours(image, [screenCnt], -1, (0, 255, 0), 2)\n",
    "cv2.imshow(\"Outline\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# apply the four point transform to obtain a top-down\n",
    "# view of the original image\n",
    "warped = four_point_transform(orig, screenCnt.reshape(4, 2) * ratio)\n",
    "\n",
    "# convert the warped image to grayscale, then threshold it\n",
    "# to give it that 'black and white' paper effect\n",
    "warped = cv2.cvtColor(warped, cv2.COLOR_BGR2GRAY)\n",
    "warped = threshold_adaptive(warped, 250, offset = 10)\n",
    "warped = warped.astype(\"uint8\") * 255\n",
    "\n",
    "# show the original and scanned images\n",
    "print(\"STEP 3: Apply perspective transform\")\n",
    "cv2.imshow(\"Original\", imutils.resize(orig, height = 650))\n",
    "cv2.imshow(\"Scanned\", imutils.resize(warped, height = 650))\n",
    "cv2.waitKey(0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "### The resulting output of the subsequent steps are:\n",
    "\n",
    "<img src= \"captures/step1ds.png\" height = 600px width = 800px style=\"float:left; margin-left = 30px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src= \"captures/step2ds.png\" height = 500px style=\"float:left; margin-left = 30px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src= \"captures/step3ds.png\" height = 600px width = 800px style=\"float:left; margin-left = 30px;\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
